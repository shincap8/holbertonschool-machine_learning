# 0x05. Regularization

### Description

This project is about regularization techniques.

### General Objectives

* What is regularization? What is its purpose?
* What is are L1 and L2 regularization? What is the difference between the two methods?
* What is dropout?
* What is early stopping?
* What is data augmentation?
* How do you implement the above regularization methods in Numpy? Tensorflow?
* What are the pros and cons of the above regularization methods?

### Mandatory Tasks

| File | Description |
| ------ | ------ |
| [0-l2_reg_cost.py](0-l2_reg_cost.py) | Calculates the cost of a neural network with L2 regularization. |
| [1-l2_reg_gradient_descent.py](1-l2_reg_gradient_descent.py) | Updates the weights and biases of a neural network using gradient descent with L2 regularization. |
| [2-l2_reg_cost.py](2-l2_reg_cost.py) | Calculates the cost of a neural network with L2 regularization. |
| [3-l2_reg_create_layer.py](3-l2_reg_create_layer.py) | Creates a tensorflow layer that includes L2 regularization. |
| [4-dropout_forward_prop.py](4-dropout_forward_prop.py) | Conducts forward propagation using Dropout. |
| [5-dropout_gradient_descent.py](5-dropout_gradient_descent.py) | Updates the weights of a neural network with Dropout regularization using gradient descent. |
| [6-dropout_create_layer.py](6-dropout_create_layer.py) | Creates a layer of a neural network using dropout. |
| [7-early_stopping.py](7-early_stopping.py) | Determines if you should stop gradient descent early. |
